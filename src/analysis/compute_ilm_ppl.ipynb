{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:16:20.606762Z",
     "start_time": "2024-10-21T15:16:20.602591Z"
    }
   },
   "id": "d38a2e3ad1f6f7cb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:16:29.646010Z",
     "start_time": "2024-10-21T15:16:21.385651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (2.18.0)\r\n",
      "Requirement already satisfied: filelock in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (3.13.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (1.24.4)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (12.0.1)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (4.66.5)\r\n",
      "Requirement already satisfied: xxhash in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (0.24.5)\r\n",
      "Requirement already satisfied: packaging in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (24.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: transformers in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (4.39.3)\r\n",
      "Requirement already satisfied: filelock in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (3.13.3)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (0.24.5)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (24.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: torch in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: filelock in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from torch) (3.13.3)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from torch) (4.10.0)\r\n",
      "Requirement already satisfied: sympy in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from torch) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (1.24.4)\r\n",
      "Requirement already satisfied: tqdm in /Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages (4.66.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:16:32.378526Z",
     "start_time": "2024-10-21T15:16:29.647525Z"
    }
   },
   "id": "e5c6cdfc39445646"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def compute_ppl(pipe, test_dataset, batch_size: int = 16, add_start_token: bool = True, device=None,\n",
    "                max_length=None, use_encoder=False\n",
    "                ):\n",
    "    # if batch_size > 1 (which generally leads to padding being required), and\n",
    "    # if there is not an already assigned pad_token, assign an existing\n",
    "    # special token to also be the padding token\n",
    "    if pipe.tokenizer.pad_token is None and batch_size > 1:\n",
    "        existing_special_tokens = list(pipe.tokenizer.special_tokens_map_extended.values())\n",
    "        # check that the model already has at least one special token defined\n",
    "        assert (\n",
    "                len(existing_special_tokens) > 0\n",
    "        ), \"If batch_size > 1, model must have at least one special token to use for padding. Please use a different model or set batch_size=1.\"\n",
    "        # assign one of the special tokens to also be the pad token\n",
    "        pipe.tokenizer.add_special_tokens({\"pad_token\": existing_special_tokens[0]})\n",
    "\n",
    "    if add_start_token and max_length:\n",
    "        # leave room for <BOS> token to be added:\n",
    "        assert (\n",
    "                pipe.tokenizer.bos_token is not None\n",
    "        ), \"Input model must already have a BOS token if using add_start_token=True. Please use a different model, or set add_start_token=False\"\n",
    "        max_tokenized_len = max_length - 1\n",
    "    else:\n",
    "        max_tokenized_len = max_length\n",
    "\n",
    "    encodings = pipe.tokenizer(\n",
    "        test_dataset[\"text\"],\n",
    "        add_special_tokens=True,\n",
    "        padding=True,\n",
    "        truncation=True if max_tokenized_len else False,\n",
    "        max_length=max_tokenized_len,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(device)\n",
    "\n",
    "    encoded_texts = encodings[\"input_ids\"]\n",
    "    attn_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "    # check that each input is long enough:\n",
    "    if add_start_token:\n",
    "        assert torch.all(torch.ge(attn_masks.sum(1), 1)), \"Each input text must be at least one token long.\"\n",
    "    else:\n",
    "        assert torch.all(\n",
    "            torch.ge(attn_masks.sum(1), 2)\n",
    "        ), \"When add_start_token=False, each input text must be at least two tokens long. Run with add_start_token=True if inputting strings of only one token, and remove all empty input strings.\"\n",
    "\n",
    "    ppls = []\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for start_index in tqdm.tqdm(range(0, len(encoded_texts), batch_size)):\n",
    "        end_index = min(start_index + batch_size, len(encoded_texts))\n",
    "        encoded_batch = encoded_texts[start_index:end_index]\n",
    "        attn_mask = attn_masks[start_index:end_index]\n",
    "\n",
    "        if use_encoder:\n",
    "            features = pipe.feature_extractor(\n",
    "                ([array[\"array\"] for array in test_dataset[\"audio\"][start_index:end_index]]), sampling_rate=16_000,\n",
    "                return_tensors=\"pt\", padding=True).to(device)\n",
    "            features[\"input_values\"] = features[\"input_features\"]\n",
    "            del features[\"input_features\"]\n",
    "            encoder_outputs = pipe.model.encoder(**features)\n",
    "            encoder_outputs = encoder_outputs.last_hidden_state\n",
    "        else:\n",
    "            encoder_outputs = None\n",
    "\n",
    "        if add_start_token:\n",
    "            bos_tokens_tensor = torch.tensor([[pipe.tokenizer.bos_token_id]] * encoded_batch.size(dim=0)).to(device)\n",
    "            encoded_batch = torch.cat([bos_tokens_tensor, encoded_batch], dim=1)\n",
    "            attn_mask = torch.cat(\n",
    "                [torch.ones(bos_tokens_tensor.size(), dtype=torch.int64).to(device), attn_mask], dim=1\n",
    "            )\n",
    "\n",
    "        labels = encoded_batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_logits = pipe.model.decoder(encoded_batch, attention_mask=attn_mask,\n",
    "                                            encoder_hidden_states=encoder_outputs).logits\n",
    "\n",
    "        shift_logits = out_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "\n",
    "        perplexity_batch = torch.exp(\n",
    "            (loss_fct(shift_logits.transpose(1, 2), shift_labels) * shift_attention_mask_batch).sum(1)\n",
    "            / shift_attention_mask_batch.sum(1)\n",
    "        )\n",
    "\n",
    "        ppls += perplexity_batch.tolist()\n",
    "\n",
    "    return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:16:32.978019Z",
     "start_time": "2024-10-21T15:16:32.384203Z"
    }
   },
   "id": "56029f0dd9929e68"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/librispeech_test.clean/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/fleurs_test/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/tedlium3_test/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/commonvoice_en_test/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/voxpopuli_test/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/librispeech_test.other/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/gigaspeech_test/data-00000-of-00001.arrow\n",
      "done\n",
      "/Users/alexanderpolok/PycharmProjects/IS24_DeCRED/data/test_transcriptions/ami_corpus_test/data-00000-of-00001.arrow\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "test_datasets = datasets.load_from_disk(\"data/test_transcriptions\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:16:43.666270Z",
     "start_time": "2024-10-21T15:16:43.614306Z"
    }
   },
   "id": "25670d76abe844d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderpolok/anaconda3/envs/huggingface_asr/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUT-FIT/DeCRED-small_False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:36<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librispeech_test.clean 129.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:05<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleurs_test 111.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:18<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tedlium3_test 89.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:24<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonvoice_en_test 141.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:38<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxpopuli_test 101.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:45<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librispeech_test.other 140.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1584/1584 [08:26<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gigaspeech_test 66.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 789/789 [02:21<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami_corpus_test 136.6\n",
      "BUT-FIT/ED-small_False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:38<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librispeech_test.clean 206.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:06<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleurs_test 159.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:18<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tedlium3_test 134.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:29<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonvoice_en_test 232.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:41<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxpopuli_test 142.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:48<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librispeech_test.other 199.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1584/1584 [08:55<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gigaspeech_test 84.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 789/789 [02:25<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami_corpus_test 308.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_id, use_encoder in [\n",
    "    (\"BUT-FIT/DeCRED-small\", False),\n",
    "    (\"BUT-FIT/ED-small\", False),\n",
    "]:\n",
    "    pipe = pipeline(\"automatic-speech-recognition\", model=model_id, feature_extractor=model_id,\n",
    "                    trust_remote_code=True, device=device)\n",
    "    pipe.type = \"seq2seq\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        pipe.model = pipe.model.to(device)\n",
    "\n",
    "    tokenizer = pipe.tokenizer\n",
    "    print(f\"{model_id}_{use_encoder}\")\n",
    "    for test_set in test_datasets:\n",
    "        test_data = test_datasets[test_set]\n",
    "        ppl = compute_ppl(pipe=pipe, test_dataset=test_data, add_start_token=True, device=device,\n",
    "                          use_encoder=use_encoder)\n",
    "        print(test_set, round(ppl[\"mean_perplexity\"],1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:47:03.253111Z",
     "start_time": "2024-10-21T15:16:48.419967Z"
    }
   },
   "id": "77d1a84626bac7b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e61153b1bf93434f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
